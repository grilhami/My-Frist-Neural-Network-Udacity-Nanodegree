# My-Frist-Neural-Network-Udacity-Nanodegree

The first project of the Udacity Nanodegree is to build my own first Neural Network. Here I was able to build and train my own Neural 
Network from scratch to predict the number of bikeshare users on a given day.

# Dependencies

-Numpy
-Matplotlib

# A couple of thing I was introduce to

# Linear Regression

Linear Regressiond is the basic of regression and commonly used for predictive analysis.

More on Linear Regression:
http://www.statisticssolutions.com/what-is-linear-regression/
https://en.wikipedia.org/wiki/Linear_regression

# NumPy

NumPy is the fundamental package for scientific computing with Python.

More on NumPy:
http://www.numpy.org
http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html
http://iamtrask.github.io/2015/07/12/basic-python-network/

# Jupyter Notebook

The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, 
visualizations and explanatory text.

More on Project Jupyter:
http://jupyter.org

# Logistic Regression

Same like Linear Regression, Logistic Regression is used for predictive analysis. It is the appropriate regression analysis to conduct 
when  the dependent variable is dichotomous (binary).

More on Logistic Regression:
http://www.statisticssolutions.com/what-is-logistic-regression/
http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/

# Perceptron

In short, Perceptron is a linear classifier. It was one of the first artificial neural network to be produced.

More on Perceptron:
https://en.wikipedia.org/wiki/Perceptron

# Gradient Descent

Gradient Descent is probabily the reason that Neural Networks are able to learn. It is an algorithm that minimizes function. Over the
years, Gradient Descent has changed and many researchs have tried to find better ways to improve this. In this project, I implemented 
a simple one.

More on Gradient Descent:
https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/

# Backpropogation

Backpropogation is a method to train Neural Networks. 

More on Backprop:
https://en.wikipedia.org/wiki/Backpropagation


